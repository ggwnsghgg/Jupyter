{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 스크레이핑 시 주의 사항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "url = \"https://www.alexa.com/topsites/countries/KR\"\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, \"lxml\")\n",
    "\n",
    "# p 태그의 요소 안에서 a 태그의 요소를 찾음\n",
    "website_ranking = soup_website_ranking.select('p a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/siteinfo/google.com\">Google.com</a>,\n",
       " <a href=\"/siteinfo/naver.com\">Naver.com</a>,\n",
       " <a href=\"/siteinfo/youtube.com\">Youtube.com</a>,\n",
       " <a href=\"/siteinfo/daum.net\">Daum.net</a>,\n",
       " <a href=\"/siteinfo/tistory.com\">Tistory.com</a>,\n",
       " <a href=\"/siteinfo/tmall.com\">Tmall.com</a>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this explanation'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_ranking_address = [website_ranking_elemnet.get_text() for website_ranking_elemnet in website_ranking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google.com',\n",
       " 'Naver.com',\n",
       " 'Youtube.com',\n",
       " 'Daum.net',\n",
       " 'Tistory.com',\n",
       " 'Tmall.com']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking_address[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Top Sites in South Korea]\n",
      "1: this explanation\n",
      "2: Google.com\n",
      "3: Naver.com\n",
      "4: Youtube.com\n",
      "5: Daum.net\n",
      "6: Tistory.com\n",
      "7: Tmall.com\n",
      "8: Facebook.com\n",
      "9: Google.co.kr\n",
      "10: Kakao.com\n"
     ]
    }
   ],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "url = \"https://www.alexa.com/topsites/countries/KR\"\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, \"lxml\")\n",
    "\n",
    "# p 태그의 요소 안에서 a 태그의 요소를 찾음\n",
    "website_ranking = soup_website_ranking.select('p a')\n",
    "website_ranking_address = [website_ranking_element.get_text() for website_ranking_element in website_ranking]\n",
    "\n",
    "print(\"[Top Sites in South Korea]\")\n",
    "for k in range(10):\n",
    "    print(\"{0}: {1}\".format(k+1, website_ranking_address[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naver.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Daum.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tistory.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Website\n",
       "1  this explanation\n",
       "2        Google.com\n",
       "3         Naver.com\n",
       "4       Youtube.com\n",
       "5          Daum.net\n",
       "6       Tistory.com"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "website_ranking_dict = {'Website': website_ranking_address}\n",
    "df = pd.DataFrame(website_ranking_dict, columns=['Website'],index=range(1,len(website_ranking_address)+1))\n",
    "df[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연도를 입력하세요 : 2020\n",
      "월을 선택하세요 : 1\n",
      "주 를 선택하세요 : 1\n",
      "[음원 랭킹 순위]\n",
      "1: METEOR\n",
      "2: Psycho\n",
      "3: Blueming\n",
      "4: HIP\n",
      "5: Square (2017)\n",
      "6: 아마두 (feat.우원재, 김효은, 넉살, Huckleberry P)\n",
      "7: Love poem\n",
      "8: 어떻게 이별까지 사랑하겠어, 널 사랑하는 거지\n",
      "9: 늦은 밤 너의 집 앞 골목길에서\n",
      "10: 흔들리는 꽃들 속에서 네 샴푸향이 느껴진거야\n",
      "11: Into the Unknown\n",
      "12: 사랑이란 멜로는 없어\n",
      "13: 안녕\n",
      "14: 오늘도 빛나는 너에게 (To You My Light) (Feat. 이라온)\n",
      "15: 시간의 바깥\n",
      "16: WINTER FLOWER(雪中梅)(Feat.RM)\n",
      "17: 조금 취했어 (Prod. 2soo)\n",
      "18: Feel Special\n",
      "19: 작은 것들을 위한 시 (Boy With Luv) (Feat. Halsey)\n",
      "20: 나의 오랜 연인에게\n",
      "21: 시든 꽃에 물을 주듯\n",
      "22: 불티 (Spark)\n",
      "23: 빌었어\n",
      "24: 숨겨진 세상 (Into the Unknown End Credit Version) (“겨울왕국 2”)\n",
      "25: 다시는 사랑하지 않고, 이별에 아파하기 싫어\n",
      "26: 2002\n",
      "27: Show Yourself\n",
      "28: 포장마차\n",
      "29: 먹구름\n",
      "30: 너를 만나\n",
      "31: 니 소식\n",
      "32: 첫 겨울이니까\n",
      "33: bad guy\n",
      "34: 있어줘요\n",
      "35: LION\n",
      "36: 워커홀릭\n",
      "37: 십이월 이십오일의 고백\n",
      "38: 기억해줘요 내 모든 날과 그때를\n",
      "39: 새 사랑\n",
      "40: 비가 내리는 날에는\n",
      "41: 사랑에 연습이 있었다면 (Prod. 2soo)\n",
      "42: 가을밤 떠난 너\n",
      "43: 모든 날, 모든 순간 (Every day, Every Moment)\n",
      "44: 사계 (Four Seasons)\n",
      "45: 날 보러 와요 (Come See Me)\n",
      "46: Señorita\n",
      "47: Popo (How deep is our love?)\n",
      "48: Obsession\n",
      "49: 헤어져줘서 고마워\n",
      "50: 너에게 못했던 내 마지막 말은\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "year = input(\"연도를 입력하세요 : \")\n",
    "month = input(\"월을 선택하세요 : \")\n",
    "week = input(\"주 를 선택하세요 : \")\n",
    "\n",
    "if len(month) == 1:\n",
    "    month = \"0\"+month\n",
    "else:\n",
    "    month = month\n",
    "# test = map(int, year, month, week)\n",
    "\n",
    "url = f\"http://music.naver.com/listen/history/index.nhn?type=TOTAL&year={year}&month={month}&week={week}\"\n",
    "\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "\n",
    "# soup.find_all(dt)\n",
    "music = soup.select('a._title')\n",
    "music_address = [website_ranking_element.get_text() for website_ranking_element in music]\n",
    "print(\"[음원 랭킹 순위]\")\n",
    "for k in range(50):\n",
    "    print(\"{0}: {1}\".format(k+1, music_address[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "탈락석으로 ‘가지마’♪ 포천의 아들 임영웅 아자!\n",
      "임영웅 ‘옛사랑’ ♪ 감성 장인 히어로 💧\n",
      "[전체HL] '신민재 끝내기' LG, 연장 혈투 끝에 키움 꺾고 준PO 진출\n",
      "‘금손아내’ 은보아, 거침없이 수리해 나가는 만능가이버!\n",
      "“후식은 중국집” 김호중×현주엽, 끝나지 않는 먹레이스!\n",
      "[4회 예고] “죽여버릴거야” 이지아, 복수의 서막 시작!\n",
      "《스페셜》 훌렁훌렁 벗지 않습니다..^^;;나혼산 100벌 챌린지 백스테이지 비하인드!\n",
      "나왔다! 찬원이의 필살기↗ ‘미운 사내’ ♬\n",
      "[선공개] 첫 차를 산 남자 공감 200% ＂조심히 타라고 했다..＂\n",
      "[선공개] 조리원 열차에 탑승한 꼬리칸 엄마 엄지원X일등칸 엄마 박하선\n",
      "“어딨니 아가야” 이지아, 친 딸 찾기 본격 시작!\n",
      "이대 목동병원 박지선 빈소…박정민, 박보영 등 동료들 조문 이어져\n",
      "[영상] 새 아파트 통째 '폭파'…中 불법 건물과의 전쟁\n",
      "“딸이 두 분 관계 알면 어떨 것 같아요?” 조수민, 김소연에 살벌한 협박!\n",
      "추미애 \"검찰총장, 정치적 중립 훼손\"...윤석열은 신임 부장검사 소집 교육\n",
      "[7AM] '포스트시즌 첫 경기부터 끝내기!' WC 1차전 하이라이트\n",
      "“내 딸 살아있어요?” 이지아, 의문의 남자로부터 걸려온 전화에 충격 오열!\n",
      "[2020 고교야구] 이제는 2022 드래프트! 주목할 유망주들은?\n",
      "“요리 못하겠어요” 김호중, 끊임없이 감시하는 먹보스 현주엽에 고통!\n",
      "“집단 린치에요! 집단!” 엄기준, 아이들이 저지른 사단에 긴급회의!\n",
      "“열심히 살았던 것뿐인데” 조수민, 혹독한 현실에 ‘눈물’\n",
      "“내 감정을 속일 수 없어요” 이지아, 엄기준에게 파혼 통보!\n",
      "영탁 ‘붓’♫ 콜센타의 자존심을 보여줘😎\n",
      "[충격] “내 딸이 아니라고?” 이지아, 나소예 친딸 아닌 사실 알고 경악!\n",
      "[충격 엔딩] “설마..내가?” 유진, 조수민과 뒤바뀐 김현수 합격에 끔찍한 의심!\n",
      "‘딸바보♥아들바보’ 오지호, 사랑스러운 ‘오남매’ 등장에 찐 웃음 만개!\n",
      "DWG vs SN 1세트\n",
      "‘삐에로는 우릴 보고 웃지’ ♪ 동원이 귀여움 대방출😊\n",
      "박지선 비보에 연예계 '침통'…안영미 생방송 중단에 SNS 추모 이어져\n",
      "[박진이 레슨] 비거리 향상 - 클럽헤드 던지는 방법\n",
      "DWG vs SN 4세트\n",
      "[꼰대인턴 OST Part 2] 이찬원 (Lee Chan Won) - 시절인연 (時節因緣) (Fate in Time) MV\n",
      "[임진한의 전국투어] 임진한의 어프로치 거리 조절 연습법\n",
      "전진♥류이서, 럭셔리 캠핑카 쇼핑 중 갑분 핑크빛 신혼♥\n",
      "함께 떠나자 뽕페스티벌🎉 속으로!!!_뽕숭아학당 26회 예고\n",
      "‘여자 이름?’ 오지호, 과거 봉인 판도라의 상자 오픈에 떨리는 심장!\n",
      "[짠내폭발] 오지호, 7년 동안 혼자 차려 먹는 셀프 밥상!\n",
      "역대 와일드카드전 명장면 모음\n",
      "[깜찍주의] 오지호♥은보아 아들 주왕이, 보아매점 털이 현장검거!\n",
      "웰뱅 피닉스(차유람) vs 신한 알파스(김가영) 2세트[신한금융투자 PBA TEAM LEAGUE 4R]\n",
      "장민호X영탁 ‘대박 날 테다’♬ 호흡대박👍\n",
      "DWG vs SN 3세트\n",
      "“너 실수했잖아” 김현수, 오디션 실수에도 합격한 최예빈에 분노!\n",
      "'대주자' 신민재, 드라마 같은 연장 끝내기 안타 / 13회말\n",
      "[단독 선공개] 박 반장의 노동요 마법♬에 걸린 갬성 식구들 (ft. 세팅 지옥🔥)\n",
      "‘에스프레소 콘파냐’ 김호중, 먹보스 감동시킨 아이스크림 믹스커피\n",
      "키움-LG 풀영상\n",
      "유진, 무자비한 ‘유전무죄 무전유죄’ 현실에 망연자실! (ft. 봉태규 얄밉)\n",
      "[14회 예고] 나 속이니까 재밌었어...?\n",
      "[단독 선공개] 유진, 김소연 앞에 무릎 꿇는 모성애! (ft. 김소연 잔혹美★)\n",
      "김희재 ‘나는 남자다’ ♫ 섹시한 골반댄스♨\n",
      "[미공개] 아침이 밝았습니다. 모두 선상 헬스장으로 모여주세요 (ft. 시선강탈 규필ㅋㅋㅋ)\n",
      "MVㅣ나훈아  - 테스형!ㅣ2020 신곡 아홉 이야기\n",
      "신민재HL - 5시간 혈투를 끝낸 극적인 끝내기의 주인공\n",
      "'대타 적중' 이천웅, 믿음에 보답하는 동점 적시타 / 13회말\n",
      "전세계가 주목한 와일드카드 명장면 TOP7\n",
      "와일드카드 1차전 시구 LG트윈스 찐팬! 홍경민 응원메시지\n",
      "“합격자는 원래 정해져있어” 진지희, 폭발 직전 김현수에 위험한 도발!\n",
      "1화#하이라이트#쉬운게 1도 없는 초보엄빠 엄지원X윤박의 산후조리원 입성기\n",
      "‘대주주 3억’ 막히자 열받았나...사표 던진 홍남기, 文대통령은 반려\n",
      "외국인 선수 전망 ② NC-두산-롯데-SK (SK 감독+한화 사장 상황)\n",
      "'담보' 4분 하이라이트 영상\n",
      "오지호, 불 맛 트레이닝으로 다져진 45세 조각 몸매★\n",
      "소원의 매혹적인 유혹💋, 하지만...!_아내의 맛 122회 예고\n",
      "이찬원 ‘카페에서’♪ 뽕 감성 촉촉☕️\n",
      "[11월1주 KBL 루머&팩트 1부] 이정현 트레이드 루머 실체. 오히려 이 트레이드가 더 확률높다\n",
      "[UCL 사전 기자회견] 알렉산더-아놀드 \"상대는 세리에A에서 가장 공격적인 팀\"\n",
      "23개월 도하영의 취향을 저격한 연잎밥\n",
      "[영상] “내 엄지를 잡는 순간 우리는 울었다”…3살 어린이 65시간 만의 ‘기적’\n",
      "웰뱅 피닉스(위마즈,차유람) vs 신한 알파스(마민캄,김가영) 4세트[신한금융투자 PBA TEAM LEAGUE 4R]\n",
      "[10분 요약]엄지원의 세상 현실적인 굴욕+고통+눈물의 출산기ZIP_세상 모든 엄마 공감\n",
      "아빠의 감동적인 '통장 편지' 발견하고 오열하는 노정의\n",
      "[WC프리뷰] 다시붙은 키움과 LG, 가을의 복수가 시작된다\n",
      "퀄리파잉 오퍼 못 받은 다나카...이유는? | 김형준\n",
      "‘조각미남과 사는 기분?’ 은보아, 다비드st 오지호와 결혼 소감!\n",
      "김희재 ‘짝사랑’ ♫ 간들어지는 첫 소절😍\n",
      "[고백 엔딩] 김하늘에게 사실을 고백한 이도현 ＂나 홍대영이야＂\n",
      "'소리도 없이' 무삭제 영상\n",
      "전진♥류이서, 캠핑카로 떠나는 ‘길바닥 신혼여행’\n",
      "엄지원X박하선, 격정적인 첫 만남♨ ＂내가 싼 거 아니야＂\n",
      "박성광♥이솔이, 모발 검사 충격 결과에 ‘위기의 탈모 부부?’\n",
      "김호중(Kim Ho Joong) X 박가빈(Park Ga Bin) - 파트너♪(원곡 남진)ㅣ김호중의파트너 EP.5\n",
      "'도합 10시간 30분 경기' 11월 2일에는 뭔가 있다?!\n",
      "＜선공개＞ 걸그룹 출신 멤버들의 영혼을 탈탈 털어버린 배윤정의 독설\n",
      "[11월 9일 예고] 은보아 울린 F4의 위험한 방문!(ft. 죄인 오지호)\n",
      "허문회 허삼영 손혁(김창현) 윌리엄스...첫 해 평가와 리더십 변화 가능성\n",
      "DWG vs SN 2세트\n",
      "영웅이의 眞짜 감성😥 ‘아내에게 바치는 노래’ ♩\n",
      "[골프백과사전] 올바른 에이밍 방법\n",
      "지하철서 '턱스크'에 술·담배…난동 승객 신고했더니?\n",
      "웰뱅 피닉스(쿠드롱) vs 신한 알파스(오성욱) 3세트[신한금융투자 PBA TEAM LEAGUE 4R]\n",
      "＂아빠 나 보러 올 거지…＂ 윤상현-노정의 눈물의 통화 \n",
      "[다시보기 4/4] 친구들 피셜(?) ＜18 어게인＞ 배우들의 학창 시절 스토리는? - 제작발표회\n",
      "홍남기, '주식시장 혼란'에 사의표명…대통령은 반려\n",
      "＂제가 터졌어요, 양수＂ 계약 성사시키자마자 양수 터진 엄지원의 프로美\n",
      "미 대선 투표, 오후 2시 시작…투표율 사상 최대 전망\n",
      "※삶과 죽음의 경계※ 무통천국은 짧고 고통은 길다... 엄지원의 험난한 출산기\n",
      "\n",
      "\n",
      "\n",
      "재생 수186,642\n",
      "재생 수136,167\n",
      "재생 수115,413\n",
      "재생 수109,980\n",
      "재생 수986,826\n",
      "재생 수119,016\n",
      "재생 수84,800\n",
      "재생 수107,556\n",
      "재생 수169,243\n",
      "재생 수34,224\n",
      "재생 수97,632\n",
      "재생 수36,097\n",
      "재생 수57,136\n",
      "재생 수84,978\n",
      "재생 수34,242\n",
      "재생 수39,915\n",
      "재생 수75,744\n",
      "재생 수6,800\n",
      "재생 수151,373\n",
      "재생 수72,157\n",
      "재생 수22,078\n",
      "재생 수51,327\n",
      "재생 수72,200\n",
      "재생 수82,521\n",
      "재생 수82,255\n",
      "재생 수92,414\n",
      "재생 수76,722\n",
      "재생 수273,384\n",
      "재생 수163,732\n",
      "재생 수175,232\n",
      "재생 수54,349\n",
      "재생 수79,405\n",
      "재생 수46,125\n",
      "재생 수141,161\n",
      "재생 수1,041,637\n",
      "재생 수8,330\n",
      "재생 수31,836\n",
      "재생 수11,540\n",
      "재생 수40,843\n",
      "재생 수47,689\n",
      "재생 수42,979\n",
      "재생 수65,877\n",
      "재생 수7,548\n",
      "재생 수49,861\n",
      "재생 수111,271\n",
      "재생 수52,616\n",
      "재생 수217,022\n",
      "재생 수7,296\n",
      "재생 수48,365\n",
      "재생 수9,534\n",
      "재생 수45,425\n",
      "재생 수124,701\n",
      "재생 수156,515\n",
      "재생 수111,660\n",
      "재생 수5,500\n",
      "재생 수779,240\n",
      "재생 수74,167\n",
      "재생 수73,249\n",
      "재생 수6,369\n",
      "재생 수27,600\n",
      "재생 수44,266\n",
      "재생 수15,287\n",
      "재생 수3,349\n",
      "재생 수22,034\n",
      "재생 수321,335\n",
      "재생 수42,910\n",
      "재생 수192,086\n",
      "재생 수126,590\n",
      "재생 수22,510\n",
      "재생 수3,812\n",
      "재생 수61,509\n",
      "재생 수5,419\n",
      "재생 수3,815\n",
      "재생 수16,832\n",
      "재생 수57,779\n",
      "재생 수12,666\n",
      "재생 수20,867\n",
      "재생 수40,539\n",
      "재생 수33,531\n",
      "재생 수124,377\n",
      "재생 수353,993\n",
      "재생 수24,543\n",
      "재생 수21,803\n",
      "재생 수24,325\n",
      "재생 수63,894\n",
      "재생 수4,638\n",
      "재생 수239,652\n",
      "재생 수29,248\n",
      "재생 수13,699\n",
      "재생 수63,977\n",
      "재생 수154,081\n",
      "재생 수3,442\n",
      "재생 수1,666\n",
      "재생 수3,675\n",
      "재생 수51,955\n",
      "재생 수67,556\n",
      "재생 수1,918\n",
      "재생 수22,144\n",
      "재생 수1,875\n",
      "재생 수16,800\n",
      "\n",
      "\n",
      "\n",
      "좋아요 수18,038\n",
      "좋아요 수304\n",
      "좋아요 수192\n",
      "좋아요 수15,899\n",
      "좋아요 수37,153\n",
      "좋아요 수1,107\n",
      "좋아요 수192\n",
      "좋아요 수9,059\n",
      "좋아요 수309\n",
      "좋아요 수143\n",
      "좋아요 수10,481\n",
      "좋아요 수86\n",
      "좋아요 수131\n",
      "좋아요 수200\n",
      "좋아요 수29\n",
      "좋아요 수12\n",
      "좋아요 수208\n",
      "좋아요 수2\n",
      "좋아요 수755\n",
      "좋아요 수151\n",
      "좋아요 수63\n",
      "좋아요 수8,116\n",
      "좋아요 수190\n",
      "좋아요 수182\n",
      "좋아요 수163\n",
      "좋아요 수7,616\n",
      "좋아요 수146\n",
      "좋아요 수425\n",
      "좋아요 수412\n",
      "좋아요 수488\n",
      "좋아요 수3,548\n",
      "좋아요 수41\n",
      "좋아요 수172\n",
      "좋아요 수941\n",
      "좋아요 수17,787\n",
      "좋아요 수12\n",
      "좋아요 수97\n",
      "좋아요 수1,504\n",
      "좋아요 수89\n",
      "좋아요 수89\n",
      "좋아요 수127\n",
      "좋아요 수123\n",
      "좋아요 수11\n",
      "좋아요 수7,382\n",
      "좋아요 수280\n",
      "좋아요 수139\n",
      "좋아요 수3,835\n",
      "좋아요 수82\n",
      "좋아요 수6,805\n",
      "좋아요 수93\n",
      "좋아요 수122\n",
      "좋아요 수738\n",
      "좋아요 수410\n",
      "좋아요 수6,024\n",
      "좋아요 수57\n",
      "좋아요 수3,236\n",
      "좋아요 수902\n",
      "좋아요 수1,205\n",
      "좋아요 수46\n",
      "좋아요 수96\n",
      "좋아요 수103\n",
      "좋아요 수75\n",
      "좋아요 수1\n",
      "좋아요 수78\n",
      "좋아요 수905\n",
      "좋아요 수84\n",
      "좋아요 수81\n",
      "좋아요 수10,864\n",
      "좋아요 수48\n",
      "좋아요 수27\n",
      "좋아요 수470\n",
      "좋아요 수22\n",
      "좋아요 수3\n",
      "좋아요 수100\n",
      "좋아요 수742\n",
      "좋아요 수31\n",
      "좋아요 수62\n",
      "좋아요 수96\n",
      "좋아요 수3,059\n",
      "좋아요 수927\n",
      "좋아요 수668\n",
      "좋아요 수92\n",
      "좋아요 수64\n",
      "좋아요 수45\n",
      "좋아요 수10,799\n",
      "좋아요 수18\n",
      "좋아요 수572\n",
      "좋아요 수43\n",
      "좋아요 수54\n",
      "좋아요 수86\n",
      "좋아요 수19,595\n",
      "좋아요 수9\n",
      "좋아요 수1\n",
      "좋아요 수4\n",
      "좋아요 수583\n",
      "좋아요 수157\n",
      "좋아요 수2\n",
      "좋아요 수85\n",
      "좋아요 수2\n",
      "좋아요 수87\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://tv.naver.com/r\"\n",
    "\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, \"lxml\")\n",
    "# print(soup)\n",
    "\n",
    "\n",
    "movie = soup.select('.cds_type')\n",
    "movie2 = soup.select('.cds_info')\n",
    "movie3 = soup.select('.title')\n",
    "movie4 = soup.select('tooltip')\n",
    "movie_name = [website_ranking_element.get_text() for website_ranking_element in movie4]\n",
    "for k in movie_name:\n",
    "    print(\"{0}\".format(k))\n",
    "        \n",
    "        \n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "hit = soup.select('.cds_info')\n",
    "hit2 = soup.select('.meta')\n",
    "hit3 = soup.select('.hit')\n",
    "\n",
    "hit_number = [test.get_text() for test in hit3]\n",
    "for k in hit_number:\n",
    "           print(k)\n",
    "\n",
    "        \n",
    "print()\n",
    "print()\n",
    "print()\n",
    "like = soup.select('.cds_info')\n",
    "like2 = soup.select('.meta')\n",
    "like3 = soup.select('.like')\n",
    "\n",
    "hit_number = [test.get_text() for test in like3]\n",
    "for k in hit_number:\n",
    "           print(k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
